<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Marcin Halupka</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Marcin Halupka</description>
    <image>
      <url>%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 22 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introduction to Hidden Markov Model</title>
      <link>/posts/introduction-to-hidden-markov-model/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/posts/introduction-to-hidden-markov-model/</guid>
      <description>The goal of this post and series is to present the foundational concept, usability, intuition of the algorithmic part and some basic axamples of Hidden Markov Models. To understand the content, basic knowledge on probability should be sufficient.
Why kind of problems I can solve with them? The ones where we observe a sequential data but we suspect that behind the scenes there may be something going on that affects the sequence we are looking at.</description>
    </item>
    
  </channel>
</rss>
